---
title: "Rick and Morty"
author: "Georgia Davidson"
date: "2024-02-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Load libraries
install.packages("RWeka")
install.packages("ggsci")

install.packages("magick", verbose=TRUE)
install.packages("slam")
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("tm")

library(dplyr)
library(readr)
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
#library(x)
#library(y)
#library(tidytext)
#library(textdata)
library(reshape2)
#library(RWeka)
library(knitr)
library(gridExtra)
library(grid)
library(magick)
library(igraph)
library(ggraph)
library("ggsci")
library(devtools)
library(circlize)
library(radarchart)
```


```{r, echo=FALSE}
# Read the data 
scripts <- read.csv("RickAndMortyScripts.csv")
scripts


# Rename Columns
#scripts = scripts %>% 
  #rename(Index = "index",
        # Season.No = "season no.",
        # Episode.No = "episode no.",
        # Episode.Name = "episode name",
#Character.Name = "name",
        # Dialog = "line")
```

```{r}

# Read the Lexicons (for sentiment classification)
bing <- read.csv("Bing.csv")
nrc <- read.csv("NRC.csv")
afinn <- read.csv("Afinn.csv")




# Head of the table
head(scripts, 4)

# Tail of the table
tail(scripts, 4)

# Summary
summary(scripts)


```


```{r}

#Creating tokens 

install.packages("tidytext")
library(tidytext)
library(dplyr)

tokens <- scripts %>% 
  mutate(dialog = as.character(scripts$line)) %>% 
  unnest_tokens(word, dialog)

tokens %>% head(5) %>% select(name, word)




#Affin score

install.packages("ggplot2")
library(ggplot2)

tokens %>% 
  # Count how many word per value
  inner_join(afinn, "word") %>% 
  count(value, sort=T) %>%
  
  # Plot
  ggplot(aes(x=value, y=n)) +
  geom_bar(stat="identity", aes(fill=n), show.legend = F, width = 0.5) +
  geom_label(aes(label=n)) +
  scale_fill_gradient(low="#85C1E9", high="#3498DB") +
  scale_x_continuous(breaks=seq(-5, 5, 1)) +
  labs(x="Score", y="Frequency", title="Word count distribution over intensity of sentiment: Neg -> Pos") +
  theme_bw()

```

```{r}

#Average Affin score for each episode

install.packages("zoo")
library(zoo)
library(dplyr)

#df %>% 
#   group_by("episode no.") %>% 
#   mutate(Average = roll(Values)) %>% 
#   ungroup()

mean(tokens$"episode no.", na.rm = TRUE) 



```




Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
